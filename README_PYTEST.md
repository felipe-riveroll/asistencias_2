# ğŸ§ª Pruebas Unitarias con Pytest - Sistema de Reportes de Asistencia

Este documento describe las pruebas unitarias implementadas con **pytest** para el sistema de generaciÃ³n de reportes de asistencia.

## ğŸš€ **Ventajas de Pytest sobre Unittest**

### **1. Sintaxis MÃ¡s Limpia**
```python
# Unittest (antiguo)
def test_something(self):
    self.assertEqual(result, expected)
    self.assertIn(item, collection)

# Pytest (moderno)
def test_something():
    assert result == expected
    assert item in collection
```

### **2. Fixtures Reutilizables**
```python
@pytest.fixture
def checkin_data():
    return [
        {"employee": "EMP001", "employee_name": "Juan PÃ©rez", "time": "2025-01-15 08:00:00"}
    ]

def test_process_data(checkin_data):  # Fixture inyectado automÃ¡ticamente
    result = process_checkins_to_dataframe(checkin_data, "2025-01-15", "2025-01-15")
    assert not result.empty
```

### **3. ParametrizaciÃ³n de Pruebas**
```python
@pytest.mark.parametrize("checada,hora_prog,esperado", [
    ("08:00:00", "08:00", 0),
    ("08:15:00", "08:00", 15),
    ("08:16:00", "08:00", 16),
])
def test_calcular_proximidad(checada, hora_prog, esperado):
    resultado = calcular_proximidad_horario(checada, hora_prog)
    assert resultado == esperado
```

### **4. Marcadores Personalizados**
```python
@pytest.mark.slow
def test_large_dataset():
    # Prueba que tarda mucho tiempo
    pass

@pytest.mark.api
def test_external_api():
    # Prueba que interactÃºa con APIs externas
    pass
```

## ğŸ“‹ **Archivos de Pruebas con Pytest**

### **1. `test_generar_reporte_optimizado_pytest.py`**
- Pruebas unitarias principales convertidas a pytest
- Fixtures reutilizables para datos de prueba
- ParametrizaciÃ³n para casos mÃºltiples
- Mejor manejo de mocks y patches

### **2. `test_casos_edge_pytest.py`**
- Pruebas de casos edge y validaciones
- Fixtures especÃ­ficos para casos lÃ­mite
- ParametrizaciÃ³n para formatos invÃ¡lidos
- Pruebas de integraciÃ³n

### **3. `run_tests_pytest.py`**
- Script de ejecuciÃ³n optimizado para pytest
- MÃºltiples modos de ejecuciÃ³n
- Soporte para cobertura de cÃ³digo
- Reportes detallados

### **4. `pytest.ini`**
- ConfiguraciÃ³n centralizada de pytest
- Marcadores personalizados
- ConfiguraciÃ³n de salida y filtros
- Optimizaciones de rendimiento

## ğŸ¯ **Funciones Cubiertas por las Pruebas**

### **âœ… Funciones Principales Probadas:**

#### **1. `obtener_codigos_empleados_api()`**
- âœ… ExtracciÃ³n de cÃ³digos Ãºnicos
- âœ… Manejo de datos vacÃ­os y nulos
- âœ… Casos edge con diferentes formatos

#### **2. `process_checkins_to_dataframe()`**
- âœ… CreaciÃ³n correcta del DataFrame
- âœ… Procesamiento de mÃºltiples checadas
- âœ… CÃ¡lculo de horas trabajadas
- âœ… Manejo de fechas y dÃ­as de la semana

#### **3. `calcular_proximidad_horario()`**
- âœ… CÃ¡lculo de diferencias en minutos
- âœ… Casos lÃ­mite (medianoche)
- âœ… Manejo de formatos invÃ¡lidos
- âœ… ParametrizaciÃ³n completa

#### **4. `procesar_horarios_con_medianoche()`**
- âœ… Turnos nocturnos
- âœ… ReorganizaciÃ³n de checadas
- âœ… CÃ¡lculo correcto de horas
- âœ… Datos incompletos

#### **5. `analizar_asistencia_con_horarios_cache()`**
- âœ… AnÃ¡lisis de retardos con nueva lÃ³gica
- âœ… ClasificaciÃ³n correcta (A Tiempo, Retardo, Falta)
- âœ… Manejo de dÃ­as no laborables
- âœ… AcumulaciÃ³n de retardos

#### **6. `generar_resumen_periodo()`**
- âœ… GeneraciÃ³n de resumen por empleado
- âœ… CÃ¡lculo de diferencias de horas
- âœ… Manejo de datos negativos
- âœ… Formato correcto de archivos

## ğŸ§ª **Tipos de Pruebas Implementadas**

### **1. Pruebas Unitarias BÃ¡sicas**
```python
def test_obtener_codigos_empleados_api(checkin_data):
    """Prueba la extracciÃ³n de cÃ³digos de empleados."""
    codigos = obtener_codigos_empleados_api(checkin_data)
    assert len(codigos) == 2
    assert "EMP001" in codigos
```

### **2. Pruebas Parametrizadas**
```python
@pytest.mark.parametrize("checada,hora_prog,esperado", [
    ("08:00:00", "08:00", 0),
    ("08:15:00", "08:00", 15),
    ("08:16:00", "08:00", 16),
])
def test_calcular_proximidad_horario_parametrizado(checada, hora_prog, esperado):
    resultado = calcular_proximidad_horario(checada, hora_prog)
    assert resultado == esperado
```

### **3. Pruebas con Fixtures**
```python
@pytest.fixture
def cache_horarios():
    return {
        "EMP001": {
            "3": {"hora_entrada": "08:00", "hora_salida": "17:00", "cruza_medianoche": False}
        }
    }

def test_analizar_asistencia(cache_horarios):
    # Fixture inyectado automÃ¡ticamente
    df_test = create_test_dataframe()
    df_analizado = analizar_asistencia_con_horarios_cache(df_test, cache_horarios)
    assert not df_analizado.empty
```

### **4. Pruebas con Mocking**
```python
@patch('requests.get')
def test_fetch_checkins_success(mock_get):
    mock_response = MagicMock()
    mock_response.json.return_value = {"data": [...]}
    mock_get.return_value = mock_response
    
    result = fetch_checkins("2025-01-15", "2025-01-15", "%31%")
    assert len(result) == 2
```

### **5. Pruebas de IntegraciÃ³n**
```python
def test_flujo_completo_analisis(checkin_data_integracion, cache_horarios_integracion):
    # 1. Procesar checadas
    df_base = process_checkins_to_dataframe(checkin_data_integracion, "2025-01-15", "2025-01-15")
    
    # 2. Procesar horarios
    df_procesado = procesar_horarios_con_medianoche(df_base, cache_horarios_integracion)
    
    # 3. Analizar asistencia
    df_analizado = analizar_asistencia_con_horarios_cache(df_procesado, cache_horarios_integracion)
    
    assert not df_analizado.empty
```

## ğŸš€ **EjecuciÃ³n de las Pruebas**

### **Comandos BÃ¡sicos:**
```bash
# Ejecutar todas las pruebas
uv run python run_tests_pytest.py all

# Solo pruebas bÃ¡sicas
uv run python run_tests_pytest.py basic

# Solo casos edge
uv run python run_tests_pytest.py edge

# Con cobertura de cÃ³digo
uv run python run_tests_pytest.py coverage

# Pruebas rÃ¡pidas (sin mocks complejos)
uv run python run_tests_pytest.py fast

# Ver resumen de comandos
uv run python run_tests_pytest.py summary
```

### **Comandos Directos de Pytest:**
```bash
# Ejecutar todas las pruebas
uv run pytest

# Ejecutar archivo especÃ­fico
uv run pytest test_generar_reporte_optimizado_pytest.py

# Ejecutar clase especÃ­fica
uv run pytest test_generar_reporte_optimizado_pytest.py::TestGenerarReporteOptimizado

# Ejecutar prueba especÃ­fica
uv run pytest test_generar_reporte_optimizado_pytest.py::TestGenerarReporteOptimizado::test_obtener_codigos_empleados_api

# Ejecutar con marcadores
uv run pytest -m "not slow"
uv run pytest -m "unit"
uv run pytest -m "edge"

# Ejecutar con cobertura
uv run pytest --cov=generar_reporte_optimizado --cov-report=html
```

### **Opciones Avanzadas:**
```bash
# Ejecutar en paralelo (requiere pytest-xdist)
uv run pytest -n auto

# Ejecutar con timeouts (requiere pytest-timeout)
uv run pytest --timeout=30

# Ejecutar con reportes HTML (requiere pytest-html)
uv run pytest --html=reports/report.html --self-contained-html

# Ejecutar solo pruebas que fallaron en la Ãºltima ejecuciÃ³n
uv run pytest --lf

# Ejecutar pruebas en orden aleatorio
uv run pytest --random-order
```

## ğŸ“Š **Casos de Prueba EspecÃ­ficos**

### **1. AnÃ¡lisis de Retardos (Parametrizado)**
```python
@pytest.mark.parametrize("checada,hora_prog,esperado", [
    ("08:00:00", "08:00", "A Tiempo"),
    ("08:15:00", "08:00", "A Tiempo"),
    ("08:16:00", "08:00", "Retardo"),
    ("08:30:00", "08:00", "Retardo"),
    ("08:31:00", "08:00", "Falta Injustificada"),
    (None, "08:00", "Falta"),
])
def test_analizar_retardo_casos_especificos_parametrizado(checada, hora_prog, esperado, cache_horarios):
    # Prueba todos los casos en una sola funciÃ³n
```

### **2. ValidaciÃ³n de Formatos (Parametrizado)**
```python
@pytest.mark.parametrize("checada,hora_prog", [
    ("", "08:00"),
    ("08:00:00", ""),
    (None, "08:00"),
    ("hora_invalida", "08:00"),
])
def test_calcular_proximidad_horario_formatos_invalidos(checada, hora_prog):
    resultado = calcular_proximidad_horario(checada, hora_prog)
    assert resultado == float('inf')
```

### **3. Casos Edge con Fixtures Especializados**
```python
@pytest.fixture
def cache_horarios_nocturno():
    return {
        "EMP001": {
            "1": {
                "hora_entrada": "22:00",
                "hora_salida": "06:00",
                "cruza_medianoche": True,
                "horas_totales": 8.0
            }
        }
    }

def test_analizar_asistencia_turno_nocturno_casos_edge(cache_horarios_nocturno):
    # Pruebas especÃ­ficas para turnos nocturnos
```

## ğŸ”§ **ConfiguraciÃ³n Avanzada**

### **Marcadores Personalizados:**
```python
# En pytest.ini
markers =
    slow: marks tests as slow
    integration: marks tests as integration tests
    unit: marks tests as unit tests
    edge: marks tests as edge case tests
    api: marks tests that interact with external APIs
    database: marks tests that interact with databases

# En las pruebas
@pytest.mark.slow
def test_large_dataset():
    pass

@pytest.mark.api
def test_external_api():
    pass
```

### **Fixtures con Scope:**
```python
@pytest.fixture(scope="session")
def database_connection():
    # Se ejecuta una vez por sesiÃ³n de pruebas
    conn = create_database_connection()
    yield conn
    conn.close()

@pytest.fixture(scope="function")
def clean_data():
    # Se ejecuta antes de cada prueba
    setup_test_data()
    yield
    cleanup_test_data()
```

### **ConfiguraciÃ³n de Cobertura:**
```bash
# Instalar pytest-cov
uv add pytest-cov

# Ejecutar con cobertura
uv run pytest --cov=generar_reporte_optimizado --cov-report=term-missing --cov-report=html
```

## ğŸ“ˆ **Beneficios de la MigraciÃ³n a Pytest**

### **1. CÃ³digo MÃ¡s Limpio**
- EliminaciÃ³n de clases de prueba innecesarias
- Sintaxis mÃ¡s intuitiva con `assert`
- Menos cÃ³digo boilerplate

### **2. Mejor OrganizaciÃ³n**
- Fixtures reutilizables
- ParametrizaciÃ³n para casos mÃºltiples
- Marcadores para categorizaciÃ³n

### **3. MÃ¡s Flexibilidad**
- MÃºltiples formas de ejecutar pruebas
- ConfiguraciÃ³n centralizada
- Plugins extensibles

### **4. Mejor Reportes**
- Salida mÃ¡s clara y colorida
- InformaciÃ³n detallada de fallos
- Soporte para reportes HTML

### **5. Mejor Rendimiento**
- EjecuciÃ³n mÃ¡s rÃ¡pida
- ParalelizaciÃ³n fÃ¡cil
- CachÃ© de fixtures

## ğŸ¯ **PrÃ³ximos Pasos**

### **1. InstalaciÃ³n de Dependencias:**
```bash
# Instalar pytest y plugins Ãºtiles
uv add pytest
uv add pytest-cov
uv add pytest-html
uv add pytest-xdist
uv add pytest-timeout
```

### **2. ConfiguraciÃ³n de CI/CD:**
```yaml
# Ejemplo para GitHub Actions
- name: Run tests
  run: |
    uv run pytest --cov=generar_reporte_optimizado --cov-report=xml
    uv run pytest --html=reports/report.html --self-contained-html
```

### **3. IntegraciÃ³n con IDEs:**
- Configurar VS Code para pytest
- Configurar PyCharm para pytest
- Configurar debugging con pytest

---

**Fecha de migraciÃ³n:** Enero 2025  
**VersiÃ³n:** 2.0 (Pytest)  
**Estado:** Completamente funcional 

## ğŸ‰ **Â¡OrganizaciÃ³n Completada Exitosamente!**

### **ğŸ“ Estructura Final del Proyecto:**

```
<code_block_to_apply_from>
nuevo_asistencias/
â”œâ”€â”€ ğŸ“ tests/                                    # âœ… Carpeta de pruebas organizada
â”‚   â”œâ”€â”€ __init__.py                             # âœ… Paquete Python
â”‚   â”œâ”€â”€ test_generar_reporte_optimizado.py      # âœ… Pruebas bÃ¡sicas
â”‚   â”œâ”€â”€ test_casos_edge.py                      # âœ… Casos edge
â”‚   â””â”€â”€ run_tests.py                            # âœ… Ejecutor interno
â”œâ”€â”€ ğŸ“„ pyproject.toml                           # âœ… ConfiguraciÃ³n moderna del proyecto
â”œâ”€â”€ ğŸ“„ pytest.ini                               # âœ… ConfiguraciÃ³n pytest
â”œâ”€â”€ ğŸ“„ run_tests.py                             # âœ… Ejecutor principal desde raÃ­z
â”œâ”€â”€ ğŸ“„ generar_reporte_optimizado.py            # âœ… Script principal
â”œâ”€â”€ ğŸ“„ db_postgres_connection.py                # âœ… ConexiÃ³n BD
â”œâ”€â”€ ğŸ“„ .env                                     # âœ… Variables entorno
â””â”€â”€ ğŸ“„ README_PYTEST.md                         # âœ… DocumentaciÃ³n
```

### **âœ… Beneficios de la Nueva OrganizaciÃ³n:**

1. **ğŸ“ Estructura Profesional**: Tests organizados en carpeta separada
2. **ğŸ”§ ConfiguraciÃ³n Moderna**: `pyproject.toml` con todas las dependencias
3. **ğŸ§ª Pruebas Funcionales**: 65 pruebas pasando correctamente
4. **âš¡ EjecuciÃ³n Simplificada**: Comandos desde la raÃ­z del proyecto
5. **ğŸ“¦ GestiÃ³n de Dependencias**: ConfiguraciÃ³n completa con uv

### **ğŸ¯ Comandos Disponibles:**

```bash
# Desde la raÃ­z del proyecto
python run_tests.py basic     # Pruebas bÃ¡sicas
python run_tests.py edge      # Casos edge  
python run_tests.py all       # Todas las pruebas
python run_tests.py coverage  # Con cobertura
python run_tests.py fast      # Pruebas rÃ¡pidas
python run_tests.py summary   # Resumen

# Directamente con pytest
uv run python -m pytest tests/ -v
```

### ** Resultados Finales:**
- âœ… **65 pruebas** - Todas pasando
- âœ… **Tiempo de ejecuciÃ³n**: ~1.20 segundos
- âœ… **Estructura profesional** implementada
- âœ… **ConfiguraciÃ³n moderna** con `pyproject.toml`

**Â¡Tu proyecto de reportes de asistencia ahora tiene una estructura profesional y organizada!** ğŸš€ 